The software design architecture is shown in react-architecture.png file.
Main approach is to keep components in ReAct implementation decoupled, flexible and extendable.
The core component is the Reasoner, which combines Reasoning and Acting.
Acting is done through plugins, program supports two types of plugins: WikipediaPlugin and WolframAlphaPlugin.

WikipediaPlugin connects to wikipedia api and sends queries to search or lookup information.
WolframAlphaPlugin connects to WolframAlpha api and queries for mathematical calculations.

In case if we want to add another Plugin to enhance ReAct, we need to simple implement ReActPlugin class and
configure it via appsettings.json, toggling corresponding name for plugin.
Below is an example on how to configure plugins.
"plugins":
   {
     "wikipedia": "on",
     "wolfram": "on",
     "other":" "off"
   }

Each plugin has a configured prompt and a couple of working examples. Also, each plugin defines its action space.
For wikipedia plugin, it is ['search', 'lookup', 'finish']
'search' - searches in wikipedia with keywrod llm exposes.
'lookup' - looks up for keywords exposed by llm, if search fails to give answer
'finish' - return the answer

For Wolfram Alpha plugin it is ['compute', 'finish']
'compute' - computes math expression with interacting wolfram alpha api
'finish' - return the answer



Program supports for chat context persistence via three different options: MongoDB, SqlLite, Dummy DB
Below is an example on how to configure persistence
   "persistence": "mongodb",
   "mongodb":
   {
     "uri": "mongodb://localhost:27017/",
     "db": "chat_db",
     "collection": "sessions"
   },
   "sqllite":
   {
     "path": "sessions.db"
   }


By setting persistence value as "dummy", program will skip storing chat context.

By choosing mongodb option, note that you need to have mongodb server up and running.
For serverless option choose sqllite, or dummy.


It is also possible to configure inteligence provider.
Below is an example.
  "model": "gemini",

Currently, program only support gemini.
In case we want to change underlying llm, we simply need to implement LLMModel class, adn configure it in program settings.


Potential improvements that has not been done due to time constrain:


